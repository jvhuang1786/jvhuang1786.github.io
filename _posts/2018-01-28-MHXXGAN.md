---
title: "MHXX GAN: Image Generation with Neural Networks"
date: 2020-03-18
tags: [neural network, data science, GAN]
header:
  image: "/mhxximg/title1.png"
excerpt: "Generative Adversarial Networks, Monster Hunter XX, Data Science"
mathjax: "true"
---

# Intro

  - The creative process is the act of making new connections from old ones.  

  The creative process is the act of making new connections between old ideas. Thus, we can say creative thinking is the task of recognizing relationships between concepts. ... Being creative isn't about being the first (or only) person to think of an idea. More often, creativity is about connecting ideas.

# Computer Requirements vs Google Colab

  - Nvidia 11gb
  - Cuda 10.0
  - cuDNN 7.6.5
  - tensorRT 6

# Vanilla GAN

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogvanilla.png" alt="GAN, capcom, mhxx" width="800" height="800">

## Generator

## Discriminator

# Backpropagation and Gradient Descent

## Backpropagation

## Gradient Descent

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/bloggradient.png" alt="GAN, capcom, mhxx" width="800" height="800">

# Data Collection

## Anime Face Data Set

[Anime Dataset](https://www.kaggle.com/splcher/animefacedataset)

## MHXX armor Data Set

[MHXX Dataset](http://mhxx-soubigazou.info)

# Image Augmentation

## Cutting in half

```python
#Splitting Image in Half
s = []
for i in range(1081):
# Read the image
    img = imageio.imread(filenames[i])
    height, width, color = img.shape

# Cut the image in half
    width_cutoff = width // 2
    s1 = img[:, :width_cutoff]
    s2 = img[:, width_cutoff:]

    s.append(s1)
    s.append(s2)
```

## Mirror

```python
#Flipping the images to get more data
flip_img = []
for i in range(2172):
    flip = np.fliplr(myarray[i])
    flip_img.append(flip)
```

## Brightness and Dimness

```python
#Testing brightness and dimness to increase dataset

data = thre_array[1000]
# expand dimension to one sample
samples = expand_dims(data, 0)
# create image data augmentation generator
datagen = ImageDataGenerator(brightness_range=[0.7,1.2])
# prepare iterator
it = datagen.flow(samples, batch_size=1)
# generate samples and plot
plt.figure(figsize = (15,10))

for i in range(6):
	# define subplot
	plt.subplot(330 + 1 + i)
	# generate batch of images
	batch = it.next()
	# convert to unsigned integers for viewing
	image = batch[0].astype('uint8')
	# plot raw pixel data
	plt.imshow(image)
# show the figure
pyplot.show()
```

* I then used photoshop to increase the resolution so we wouldn't get any blurry images.

## Dimension

```python
#The files will be saved in a newly created folder called output
import Augmentor
p = Augmentor.Pipeline('mhxx_800px')
p.resize(probability = 1.0, width = 512, height = 512)
p.random_color(probability = 1.0, min_factor = 0.5, max_factor = 0.9)

#Now transform all our images to 256x256
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
p.process()
```
* We then use fastai to check the images to see if tfrecords will read without error.
* Use dataset_tool.py to change images to tfrecords

[Image Augment Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/mhxx_dataprep.ipynb)

# Convolutional Neural Networks

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogdcstructure.png" alt="GAN, capcom, mhxx" width="800" height="800">

## VGG16 Keras Model Feature Map

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogvgg.png" alt="GAN, capcom, mhxx" width="800" height="800">

[Feature Map Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/feature_map.ipynb)

# Deep Convolutional GAN

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blog2000.png" alt="GAN, capcom, mhxx" width="800" height="800">

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogdcgan.gif" alt="GAN, capcom, mhxx" width="800" height="800">

[DCGAN Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/dcgan_mhxx.ipynb)

#Image Metrics

## Inception Score

  - V3 Model

## Frechet Inception Distance

[Freceht Inception Distance Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/frechet_inception_distance.ipynb)

## Perception Path Length

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogppl.png" alt="GAN, capcom, mhxx" width="800" height="800">

# Style GAN

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogsgantrain.gif" alt="GAN, capcom, mhxx" width="800" height="800">


## Anime

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/bloganimeface.gif" alt="GAN, capcom, mhxx" width="800" height="800">

## MHXX

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogmode.png" alt="GAN, capcom, mhxx" width="800" height="800">

## Transfer Learning

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogtransfer.png" alt="GAN, capcom, mhxx" width="800" height="800">

[Style GAN Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/mhxx_stylegan.ipynb)

## TensorBoard

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/blogloss.png" alt="GAN, capcom, mhxx" width="800" height="1200">

## Generated Images

<img src="{{ site.url }}{{ site.baseurl }}/mhxximg/bloggenerate.gif" alt="GAN, capcom, mhxx" width="600" height="800">

[Generate Image Github](https://nbviewer.jupyter.org/github/jvhuang1786/mhxxCapStone/blob/master/img_generate.ipynb)
## Future Work

*Slide Deck, Full Write up and Github link below*

* [MHXX Slide Deck](https://docs.google.com/presentation/d/1YD-FdvndoCUBrLOgn2Q1wNcbezX3Ry8AbWru7tPmSfA/edit#slide=id.p1)

* [MHXX GAN Full Write Up](https://docs.google.com/document/d/1pgZfQyXih_lmArl-OqA81ylXD48rHplDr4idt_k2seQ/edit)

* [MHXX GAN Github Link](https://github.com/jvhuang1786/mhxxCapStone)
